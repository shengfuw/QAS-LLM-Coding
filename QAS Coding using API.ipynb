{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QAS Coding Using LLM (API Version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set file path, api key, model, and prompt version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = \"Copy of GSS QAS LLM RCoding 2024.xlsx\" # \"testing.xlsx\"\n",
    "sheet_name = \"All GSS items for LLM\"\n",
    "QAS_pdf_file_path = \"QAS-99 Manual.pdf\"\n",
    "\n",
    "model = \"gpt-4o-mini\" # \"gpt-4o\" or \"gpt-4o-mini\"\n",
    "prompt_version = 3 # 1, 2, or 3\n",
    "\n",
    "api_key = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Border, Side\n",
    "from openpyxl.styles import Font, Alignment, PatternFill\n",
    "from openpyxl.utils import get_column_letter\n",
    "\n",
    "with open('prompts/prompt_v1.txt', 'r', encoding='utf-8') as file:\n",
    "    prompt_v1 = file.read()\n",
    "\n",
    "with open('prompts/prompt_v2.txt', 'r', encoding='utf-8') as file:\n",
    "    prompt_v2 = file.read()\n",
    "\n",
    "with open('prompts/prompt_v3.txt', 'r', encoding='utf-8') as file:\n",
    "    prompt_v3 = file.read()\n",
    "\n",
    "if prompt_version == 1:\n",
    "    prompt = prompt_v1\n",
    "elif prompt_version == 2:\n",
    "    prompt = prompt_v2\n",
    "elif prompt_version == 3:\n",
    "    prompt = prompt_v3\n",
    "\n",
    "def create_a_thread(client, prompt, QAS_pdf_file_path):\n",
    "    if prompt_version == 1 or prompt_version == 2:\n",
    "        thread = client.beta.threads.create(\n",
    "            messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "            ]\n",
    "        )\n",
    "    elif prompt_version == 3:\n",
    "        message_file = client.files.create(\n",
    "            file=open(QAS_pdf_file_path, \"rb\"), purpose=\"assistants\"\n",
    "        )\n",
    "\n",
    "        thread = client.beta.threads.create(\n",
    "            messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "                # Attach the new file to the message.\n",
    "                \"attachments\": [{\"file_id\": message_file.id, \"tools\": [{\"type\": \"file_search\"}]}],\n",
    "            }\n",
    "            ]\n",
    "        )\n",
    "        # print(thread.tool_resources.file_search)\n",
    "    \n",
    "    return thread\n",
    "\n",
    "\n",
    "def run_a_message(client, thread_id, assistant_id, content):\n",
    "    message = client.beta.threads.messages.create(\n",
    "        thread_id=thread_id,\n",
    "        role=\"user\",\n",
    "        content=content\n",
    "    )\n",
    "\n",
    "    run = client.beta.threads.runs.create(thread_id=thread_id, assistant_id=assistant_id, instructions=\"Please follow the QAS and provide an answer in the intended format.\")\n",
    "\n",
    "    while run.status != \"completed\":\n",
    "        run = client.beta.threads.runs.retrieve(thread_id=thread_id, run_id=run.id)\n",
    "        time.sleep(1)\n",
    "\n",
    "    message_response = client.beta.threads.messages.list(thread_id=thread_id)\n",
    "    message_response = message_response.data\n",
    "    return message_response[0].content[0].text.value\n",
    "\n",
    "\n",
    "def process_response(response):\n",
    "    # 1. Extract variables and values using regular expressions\n",
    "    variable_match = re.findall(r'(\\d+[a-z])\\. (\\d+)', response)\n",
    "    coding_results = {variable: int(value) for variable, value in variable_match}\n",
    "    QAS_issues = ['1a', '1b', '1c', '2a', '2b', '3a', '3b', '3c', '3d', '4a', '4b', '4c', '5a', '5b', '5c', '5d', '6a', '6b', '6c', '7a', '7b', '7c', '7d', '7e', '7f', '7g', '8a']\n",
    "    for issue in QAS_issues:\n",
    "        if issue not in coding_results:\n",
    "            coding_results[issue] = 0\n",
    "    coding_results = dict(sorted(coding_results.items()))\n",
    "\n",
    "    # 2. Calculate the sum\n",
    "    all_sum = sum(coding_results.values())\n",
    "\n",
    "    category_totals = {}\n",
    "    for key, value in coding_results.items():\n",
    "        main_category = key[0]  # Extract the main category as the numeric part of the key (e.g., '1' from '1a')\n",
    "\n",
    "        if main_category in category_totals:\n",
    "            category_totals[main_category] += value\n",
    "        else:\n",
    "            category_totals[main_category] = value\n",
    "\n",
    "    # 3. Extract the explanation\n",
    "    explanation_match = re.search(r'Explanations?:\\s*(.*)', response)\n",
    "    if explanation_match:\n",
    "        explanation = explanation_match.group(1)\n",
    "    else:\n",
    "        explanation = \"\"\n",
    "    \n",
    "    # 4. Create a DataFrame with a single row for the wide format\n",
    "    combined_results = pd.DataFrame({**coding_results, 'Explanations': explanation, 'Sum-All': all_sum}, index=[0])\n",
    "    \n",
    "    for category, category_sum in category_totals.items():\n",
    "        combined_results[f'Sum-{category}'] = category_sum\n",
    "    \n",
    "    return combined_results\n",
    "\n",
    "\n",
    "def save_result_to_file(df, output_file_path):\n",
    "    if os.path.exists(output_file_path):\n",
    "        # If file exists, append to it\n",
    "        writer = pd.ExcelWriter(output_file_path, engine='openpyxl', mode='a', if_sheet_exists='overlay')\n",
    "        startrow = list(writer.sheets.values())[0].max_row\n",
    "        df.to_excel(writer, index=False, header=False, startrow=startrow)\n",
    "        writer.close()\n",
    "    else:\n",
    "        # If file doesn't exist, create a new one and format it\n",
    "        df.to_excel(output_file_path, index=False)\n",
    "\n",
    "    wb = load_workbook(output_file_path)\n",
    "    ws = wb.active\n",
    "\n",
    "    no_border = Border(left=Side(border_style=None),right=Side(border_style=None), top=Side(border_style=None), bottom=Side(border_style=None))\n",
    "    for row in ws.iter_rows():\n",
    "        for cell in row:\n",
    "            cell.border = no_border\n",
    "            cell.alignment = Alignment(horizontal=\"center\", vertical=\"center\")\n",
    "\n",
    "    for row in range(2, ws.max_row + 1):\n",
    "        ws.row_dimensions[row].height = 120\n",
    "\n",
    "    for col in ws.iter_cols(min_col=1, max_col=ws.max_column):\n",
    "        col_name = col[0].value\n",
    "        col_letter = get_column_letter(col[0].column)\n",
    "        if col_name in ['Variable Name', 'LLM Model', 'Prompt Version', 'Testing Time']:\n",
    "            ws.column_dimensions[col_letter].width = 15\n",
    "        elif col_name in ['Full Question Wording', 'Explanations']:\n",
    "            ws.column_dimensions[col_letter].width = 50\n",
    "            for cell in col:\n",
    "                cell.alignment = Alignment(horizontal=\"left\", vertical=\"top\", wrap_text=True)\n",
    "        elif col_name == 'LLM Coding Results':\n",
    "            ws.column_dimensions[col_letter].width = 20\n",
    "            for cell in col:\n",
    "                cell.alignment = Alignment(horizontal=\"left\", vertical=\"center\", wrap_text=False)\n",
    "        else:\n",
    "            ws.column_dimensions[col_letter].width = 8\n",
    "\n",
    "    for cell in ws[\"A1:AQ1\"][0]:  # Header formatting\n",
    "        cell.font = Font(bold=True)\n",
    "        cell.fill = PatternFill(\"solid\", fgColor=\"00C0C0C0\")\n",
    "        cell.alignment = Alignment(horizontal=\"center\", vertical=\"center\")\n",
    "\n",
    "    for row in range(1, ws.max_row+1): \n",
    "        ws[f'B{row}'].border = Border(right=Side(style=\"thin\"))\n",
    "        ws[f'F{row}'].border = Border(right=Side(style=\"thin\"))\n",
    "        ws[f'AH{row}'].border = Border(right=Side(style=\"thin\"))\n",
    "\n",
    "    wb.save(output_file_path)\n",
    "\n",
    "def save_result_to_existing_file(df, output_file_path):\n",
    "    writer = pd.ExcelWriter(output_file_path, engine='openpyxl', mode='a', if_sheet_exists='overlay')\n",
    "    startrow = list(writer.sheets.values())[0].max_row\n",
    "    df.to_excel(writer, index=False, header=False, startrow=startrow)\n",
    "    writer.close()\n",
    "\n",
    "def clean_up(client): # clear up all the assistants, vector stores, and files\n",
    "    for assistant in client.beta.assistants.list().data:\n",
    "        client.beta.assistants.delete(assistant.id)\n",
    "    for vector_store in client.beta.vector_stores.list().data:\n",
    "        client.beta.vector_stores.delete(vector_store.id)\n",
    "    for file in client.files.list().data:\n",
    "        client.files.delete(file.id)\n",
    "    return len(client.beta.assistants.list().data), len(client.beta.vector_stores.list().data), len(client.files.list().data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the excel file as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input = pd.read_excel(input_file_path, engine='openpyxl', sheet_name=sheet_name)\n",
    "df_input.loc[df_input['Variable Name'].isna(), 'Variable Name'] = 'none' # Fill missing variable names with 'none'\n",
    "df_input = df_input.loc[~df_input['Variable Name'].str.contains('Notes')] # Remove rows whos variable name contains 'Notes'\n",
    "df_input['Combined'] = df_input['Variable Name'] + ': ' + df_input['Full Question Wording']\n",
    "df_input = df_input.dropna(subset=['Full Question Wording'])\n",
    "df_input = df_input.reset_index(drop=True)\n",
    "\n",
    "print(\"Number of rows in df_input: \", len(df_input))\n",
    "\n",
    "# Only run the questions in m to n-1 rows!\n",
    "df_output = df_input.iloc[120:].copy()\n",
    "\n",
    "df_output[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] ~60\n",
    "- [x] 60~120\n",
    "- [ ] 120~180\n",
    "- [ ] 180~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the main coding process\n",
    "\n",
    "[🔗 Check OpenAI API usage](https://platform.openai.com/usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create an assistant\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "if prompt_version == 1 or prompt_version == 2:\n",
    "    assistant = client.beta.assistants.create(\n",
    "        name=\"QAS Coder\",\n",
    "        instructions=prompt,\n",
    "        model=model,\n",
    "    )\n",
    "    vector_store_id = None\n",
    "elif prompt_version == 3:\n",
    "    # Step 1: Create a new Assistant with File Search Enabled\n",
    "    assistant = client.beta.assistants.create(\n",
    "        name=\"QAS Coder\",\n",
    "        instructions=prompt,\n",
    "        model=model,\n",
    "        tools=[{\"type\": \"file_search\"}]\n",
    "    )\n",
    "    # Step 2: Upload files and add them to a Vector Store\n",
    "    vector_store = client.beta.vector_stores.create(name=\"QAS PDF\")\n",
    "    vector_store_id = vector_store.id\n",
    "    file_paths = [QAS_pdf_file_path]\n",
    "    file_streams = [open(path, \"rb\") for path in file_paths]\n",
    "    file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "        vector_store_id=vector_store.id, files=file_streams\n",
    "    )\n",
    "    # Step 3: Update the assistant to use the new Vector Store\n",
    "    assistant = client.beta.assistants.update(\n",
    "        assistant_id=assistant.id,\n",
    "        tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
    "    )\n",
    "    # print(file_batch.status)\n",
    "    # print(file_batch.file_counts)\n",
    "\n",
    "# 2. Create a new thread\n",
    "thread = create_a_thread(client, prompt, QAS_pdf_file_path)\n",
    "\n",
    "# 3. Process each question and store the results in the DataFrame\n",
    "print(f\"The number of questions to be coded: {len(df_output)}\\nStarting the coding process...\", end='')\n",
    "for index, row in df_output.iterrows():\n",
    "    print(index+1, end='.')\n",
    "    question = row['Combined']\n",
    "\n",
    "    # every 20 questions, create a new thread (i.e., start a new conversation) \n",
    "    if index % 20 == 19:\n",
    "        thread = create_a_thread(client, prompt, QAS_pdf_file_path)\n",
    "        print('\\n', end='')\n",
    "\n",
    "    # send the question to the thread and get the response\n",
    "    response = run_a_message(client, thread.id, assistant.id, question)\n",
    "    print('..', end='')\n",
    "\n",
    "    df_output.at[index, 'LLM Model'] = model\n",
    "    df_output.at[index, 'Prompt Version'] = prompt_version\n",
    "    df_output.at[index, 'Testing Time'] = time.strftime(\"%Y-%m-%d %H:%M\")\n",
    "    df_output.at[index, 'LLM Coding Results'] = response\n",
    "\n",
    "    # put the processed reponse after the end of this row \n",
    "    processed_response = process_response(response)\n",
    "    for col in processed_response.columns:\n",
    "        df_output.at[index, col] = processed_response[col].values\n",
    "\n",
    "df_output.drop(columns=['Combined'], inplace=True)\n",
    "\n",
    "# 4. Save the results to a new Excel file\n",
    "output_file_path = input_file_path.replace(\".xlsx\", \"_results.xlsx\")\n",
    "\n",
    "save_result_to_file(df_output, output_file_path)\n",
    "print(f' \"{output_file_path}\" Saved! It contains the coding results for {pd.read_excel(output_file_path).shape[0]} questions in total.')\n",
    "clean_up(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every 60 survey questions, it takes how many minutes and how much money:\n",
    "-  **gpt-4o-mini + prompt version 1**: 13m; 0.06 USD\n",
    "-  **gpt-4o-mini + prompt version 2**: 11m; 0.12 USD \n",
    "-  **gpt-4o-mini + prompt version 3**: 18m; 0.25 USD"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
